# Model Import Fix - Path Handling & API Issues

## Problem
Model import was showing success but models weren't registering. Investigation revealed a **400 Bad Request** from Ollama: `"neither 'from' or 'files' was specified"` when trying to import GGUF files via the `/api/create` endpoint, regardless of path formatting.

## Root Cause
**Ollama 0.13.5 has a bug in the `/api/create` API endpoint** where it doesn't properly parse modelfile content sent via the API, even though the same modelfile works perfectly with the CLI `ollama create` command.

Testing showed:
- âœ“ CLI: `ollama create model -f Modelfile` **WORKS**
- âœ— API: `POST /api/create` with modelfile content **FAILS**
- All tested formats failed: `FROM "path"`, `from 'path'`, `from path`, etc.
- Error message: `{"error":"neither 'from' or 'files' was specified"}`

## Solution Applied

### Changed from API to CLI Approach
Since the Ollama API has issues but the CLI works reliably, the import function now:

1. **Creates a temporary Modelfile** with the GGUF path
2. **Uses `subprocess.Popen`** to run `ollama create` CLI command
3. **Streams output** from the process to update the progress dialog
4. **Cleans up** the temp file after completion

### Implementation (ollama_chat.py)

```python
# Create temp modelfile
with tempfile.NamedTemporaryFile(mode='w', suffix='_modelfile', delete=False) as f:
    f.write(f'FROM "{modelfile_path}"')
    temp_modelfile = f.name

# Run CLI command
cmd = ["ollama.exe", "create", model_name, "-f", temp_modelfile]
process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)

# Monitor progress and update UI
while True:
    line = process.stdout.readline()
    if not line and process.poll() is not None:
        break
    progress.setLabelText(f"Importing...\\n\\n{line}")
    QApplication.processEvents()
```

### Benefits of CLI Approach
- âœ“ **Works reliably** with paths containing spaces
- âœ“ **Real-time progress** updates from ollama
- âœ“ **Cancellable** - user can cancel during import
- âœ“ **Robust error handling** - gets actual error messages from ollama
- âœ“ **Future-proof** - uses official CLI interface

## Testing Utilities Created

### 1. test_model_import.py
Tests different modelfile formats via the API (for debugging):
```bash
python tools/test_model_import.py "C:/path/to/model.gguf"
```

### 2. test_model_import_v2.py
Tests different API payload structures:
```bash
python tools/test_model_import_v2.py "C:/path/to/model.gguf"
```

### 3. test_api_create.py
Focused test for the /api/create endpoint:
```bash
python tools/test_api_create.py
```

All three utilities confirmed the API endpoint doesn't work in Ollama 0.13.5.

## Testing the Fix

1. **Start AuraNexus**
   ```bash
   python launch.py
   ```

2. **Import a model**
   - Click the ðŸ“‚ button next to model dropdown
   - Select a GGUF file (paths with spaces are fine!)
   - Enter a model name
   - Watch real-time progress

3. **Verify in terminal**
   - See ollama CLI output
   - Model shows in dropdown after completion

4. **Test with llama3.2 or similar**
   ```bash
   # The working test case:
   ollama list  # Should show your imported model
   ```

## Workarounds Tested (All Failed)

- Single quotes: `from 'path'`  
- Double quotes: `from "path"`
- Uppercase FROM: `FROM "path"`
- Lowercase from: `from "path"`
- No quotes: `from path`
- Escaped spaces: `from path\\ with\\ spaces`
- Different API fields: `name` vs `model`
- Stream vs non-stream
- Direct `from` field (not modelfile)

**None worked with the API.** Only the CLI succeeded.

## Known Issues

### Ollama API Bug
The `/api/create` endpoint in Ollama 0.13.5 doesn't properly parse modelfile content. This may be fixed in future versions.

### Temporary Workaround
AuraNexus now uses the CLI, which:
- Requires `ollama` or `ollama.exe` in PATH
- Creates temporary files (cleaned up after)
- Works cross-platform (Windows/Linux/Mac)

## Future Improvements
- [ ] Monitor Ollama releases for API fix
- [ ] Add optional API fallback when fixed
- [ ] Cache validation to prevent duplicate imports
- [ ] Batch import multiple models
- [ ] Drag-and-drop GGUF files

## Related Files Modified
- [src/ollama_chat.py](src/ollama_chat.py) - Import function now uses CLI
- [src/ollama_client.py](src/ollama_client.py) - Enhanced error reporting (kept for other features)
- [tools/test_model_import.py](tools/test_model_import.py) - API testing utility
- [tools/test_model_import_v2.py](tools/test_model_import_v2.py) - Payload format testing
- [tools/test_api_create.py](tools/test_api_create.py) - Focused API test

## References
- Ollama CLI Documentation: https://github.com/ollama/ollama
- Ollama API Documentation: https://github.com/ollama/ollama/blob/main/docs/api.md
- Modelfile Syntax: https://github.com/ollama/ollama/blob/main/docs/modelfile.md

