[package]
name = "auranexus"
version = "2.0.0"
description = "AuraNexus - HIPAA-Compliant AI Companion (Native Rust)"
authors = ["AuraNexus Team"]
license = ""
repository = ""
edition = "2021"

[build-dependencies]
tauri-build = { version = "1.5", features = [] }

[dependencies]
# Tauri core
tauri = { version = "1.5", features = ["api-all"] }
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"

# Async runtime
tokio = { version = "1", features = ["full"] }

# LLM inference (native Rust, CPU-only for now)
llama-cpp-2 = { version = "0.1", features = [] }
# NOTE: GPU support (CUDA/Vulkan) has build issues on Windows - CPU works reliably

# Vector database (embedded) - We'll implement embeddings separately
# lancedb = "0.5"  # Temporarily disabled due to protobuf complexity

# Additional utilities
anyhow = "1.0"
thiserror = "1.0"
chrono = { version = "0.4", features = ["serde"] }
uuid = { version = "1.0", features = ["v4", "serde"] }
parking_lot = "0.12"

[features]
default = []
custom-protocol = ["tauri/custom-protocol"]
